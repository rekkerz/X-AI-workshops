{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X-AI Workshop2: Python Gym.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "xz23TsN4ZJsG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rekkerz/X-AI-workshops/blob/master/X_AI_Workshop2_Python_Gym.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odNaDE1zyrL2",
        "colab_type": "text"
      },
      "source": [
        "# Install dependancies, takes around 45 seconds\n",
        "\n",
        "Rendering Dependancies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AxnvAVyzQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A-1LTSH88EE",
        "colab_type": "text"
      },
      "source": [
        "Installing Dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCelFzWY9MBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXSx7hg19TH",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdb2JwZy4jGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from gym import wrappers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQEtc28G4niA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9UWeToN4r7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3BGbWOu179M",
        "colab_type": "text"
      },
      "source": [
        "# Cartpole!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGEFMfDOzLen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"CartPole-v1\") # Here we would select the environment\n",
        "env = wrap_env(env)           # We need to wrap the environment to use it in Google Colab."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BmIlXhe9Q89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(env.action_space)       # This shows us the action space. In case of cartpole you can move left or right so action space is 2.\n",
        "print(env.observation_space)  # This shows the observation space."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndJtk4VlKHbD",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the environment works by using it with a default movement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nj5sjsk15IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "episodes = 100\n",
        "observation = env.reset()\n",
        "\n",
        "for _ in range(episodes):\n",
        "    env.render()\n",
        "    action = env.action_space.sample() # This is a random movement at the moment.\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    \n",
        "    if done:\n",
        "      print(\"Observation = \",observation)\n",
        "      print(\"Info = \",info)\n",
        "      break;\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzn_-3r6JSP4",
        "colab_type": "text"
      },
      "source": [
        "# Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPfTlGptKPTE",
        "colab_type": "text"
      },
      "source": [
        "Currently the pole makes a random movement out it's action space. The goal of this simulation is to balance the pole. There are many approaches to this (some of them won't be covered)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1szvpf-KX3Yc",
        "colab_type": "text"
      },
      "source": [
        "## Moving left and right repeatedly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQOYrmcpX8MG",
        "colab_type": "text"
      },
      "source": [
        "In this approach we will simply move left and right repeatedly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdEDGR2yYDkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "observation = env.reset()\n",
        "right = True\n",
        "for _ in range(1000):\n",
        "  env.render()\n",
        "\n",
        "  if(right == True):\n",
        "    action = 1\n",
        "    right = False\n",
        "  else:\n",
        "    action = 0\n",
        "    right = True\n",
        "    \n",
        "  observation, reward, done, info = env.step(action)\n",
        "\n",
        "  if done:\n",
        "    observation = env.reset()\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf3i0zXmKd-_",
        "colab_type": "text"
      },
      "source": [
        "### Using Weight Vector\n",
        "\n",
        "The idea of this approach revolves around the position of the pole.\n",
        "\n",
        "Action = 1 if np.dot(observation,new_weights) > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qmq1vuORo2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestLength = 0\n",
        "episode_length = []\n",
        "best_weights = np.zeros(4)    # Generates an array of 4 zeros.\n",
        "flag = 0\n",
        "max_life = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nUQnZUHSEjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = wrap_env(gym.make(\"CartPole-v1\"))\n",
        "\n",
        "for i in range(1):   # There will be 1 trial.\n",
        "  new_weights = np.random.uniform(-1,1,4) # generates an array of 4 int between in range(-1,1)\n",
        "  length = []\n",
        "  for j in range(500):  # There will be 500 timesteps \n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    count = 0\n",
        "    while not done:\n",
        "      count += 1\n",
        "      action = 0 if np.dot(observation,new_weights) >0 else 1  \n",
        "      # This defines the method used. Will be explained by presenter.\n",
        "      observation,reward,done,_ = env.step(action)\n",
        "      if done:\n",
        "        break\n",
        "      elif count > max_life:\n",
        "        flag = 1\n",
        "        break\n",
        "    length.append(count)\n",
        "  avg_length = float(sum(length)/ len(length))\n",
        "  print(\"Average length = \", avg_length)\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9LoZNssbkRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env= wrappers.Monitor(env, 'brute_force_files', force = True)\n",
        "done=  False\n",
        "count = 0\n",
        "observation = env.reset()\n",
        "\n",
        "while not done:\n",
        "    count = count +1\n",
        "    action = 1 if np.dot(observation,best_weights) >0 else 0\n",
        "    observation,reward,done,_ = env.step(action)\n",
        "    if done:\n",
        "        break\n",
        "print('with best weights, game lasted ',count , ' moves')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz23TsN4ZJsG",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PawuxxduZPJT",
        "colab_type": "text"
      },
      "source": [
        "A neural network will be deeper cover in the next lecture."
      ]
    }
  ]
}